# 专业术语表

> **参考资源**
>
> - [Google Developers 机器学习术语表](https://developers.google.com/machine-learning/glossary)
> - [ML-Glossary](https://ml-cheatsheet.readthedocs.io/en/latest/index.html)
> - [人工智能术语表 - Wikipedia](https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence)

## 基础数学

| 术语                                          | 定义与说明                                                                                                                                                                                                                                                                     |
| --------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **点乘**<br>（Dot product / Scalar product）  | - 又称数量积或向量内积，结果为标量<br>- 代数定义：$\mathbf{a}\cdot\mathbf{b}=\sum_{i=1}^n a_i b_i$<br>- 几何定义：$\mathbf{a}\cdot\mathbf{b}=\|\mathbf{a}\|\|\mathbf{b}\|\cos\theta$（限于二维和三维）<br>- 反映两个向量的相似度，相似度越高点乘越大<br>- 规范化后表示夹角余弦 |
| **叉乘**<br>（Cross product）                 | - 又称向量积或向量外积，结果为垂直于原向量的新向量<br>- 几何定义：$\mathbf{a}\times\mathbf{b}=\|\mathbf{a}\|\|\mathbf{b}\|\sin\theta$<br>- 记号：$\mathbf{a}\times\mathbf{b}$ 或 $\mathbf{a}\land\mathbf{b}$<br>- 模长等于以两向量为边的平行四边形面积                         |
| **一般矩阵乘积**<br>（Matrix multiplication） | - 记号：$\mathbf{AB}$ 或 $\mathbf{A}\cdot\mathbf{B}$<br>- 代数定义：$(\mathbf{AB})_{ij}=\sum_{r=1}^n a_{ir}b_{rj}$<br>- 可视为行向量与列向量的内积                                                                                                                             |
| **哈达玛乘积**<br>（Hadamard product）        | - 又称逐元素乘积（element-wise product）<br>- 输入：两个相同形状的矩阵<br>- 数学定义：$(\mathbf{A}\circ\mathbf{B})_{ij}=a_{ij}b_{ij}$                                                                                                                                          |
| **张成**                                      | 由线性无关的基向量所能表示的所有空间向量的集合                                                                                                                                                                                                                                 |
| **张量**<br>（Tensor）                        | - 0维：标量，1维：向量，2维：矩阵，3维及以上：张量<br>- 数学中对多维数据的抽象描述<br>- NumPy中的ndarray是多维数组的实现<br>- 元素不限于数值，可为字符串等类型                                                                                                                 |
| **解析解**                                    | 能用公式明确表达的精确解（如线性回归），但并非所有问题都存在解析解                                                                                                                                                                                                             |

## 机器学习

| 术语                           | 定义与说明                                                                                                                                                |
| ------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **样本/特征向量/示例**         | 由属性值构成的数据行，记为 $\mathbf{x}$                                                                                                                   |
| **标签**<br>（Labels）         | 对样本的标记，记为 $y$                                                                                                                                    |
| **样例**<br>（Samples）        | 由 $\mathbf{x}$ 和 $y$ 共同组成的数据单元                                                                                                                 |
| **属性空间/样本空间/输入空间** | 由属性张成的空间，记为 $\mathbf{X}$                                                                                                                       |
| **标记空间/输出空间**          | 由标签张成的空间，记为 $\mathbf{Y}$                                                                                                                       |
| **数据集**<br>（Data Set）     | 所有样例的集合                                                                                                                                            |
| **Batch**                      | 多个样例组成的子集，用于随机梯度下降中更新网络参数                                                                                                        |
| **归一化**                     | - 将数据缩放到[0,1]区间<br>- 消除量纲影响，但对异常值敏感                                                                                                 |
| **标准化**                     | - 使数据符合高斯分布<br>- 常用批标准化（BN）加速收敛                                                                                                      |
| **规范化**                     | 归一化与标准化的统称                                                                                                                                      |
| **正则化**                     | - 解决模型过拟合问题<br>- 常用L1、L2正则化[[1]][[2]]                                                                                                      |
| **嵌入**<br>（Embeddings）     | 将高维向量映射到低维空间的技术                                                                                                                            |
| **全连接层**                   | 又称稠密层（Dense layer）                                                                                                                                 |
| **迁移学习**                   | - 将已学习好的源任务知识迁移到目标任务<br>- 过程：$\theta^*=\arg \min_{\theta} \mathcal{L}(\theta\|\theta_0, \mathcal{D})$<br>- 常用微调（fine-tune）实现 |
| **基于度量学习的方法**         | 学习映射使同类样本在嵌入空间中距离相近，异类样本距离较远                                                                                                  |
| **优化器**                     | 寻找最优参数的方法（如梯度下降法）                                                                                                                        |
| **深度学习**                   | 针对特定任务从零开始学习并应用                                                                                                                            |
| **元学习**                     | - 学会自主学习的先验知识<br>- 用任务进行训练，应用于新任务<br>- 元学习是方法，小样本学习是场景                                                            |
| **小样本学习**                 | - 基于先验知识进行学习<br>- 输入多张图片，输出相似度<br>- 通过Support Set提供额外信息                                                                     |
| **Support Set**                | 预测时提供额外信息的小数据集，类似于"查手册"                                                                                                              |
| **Train Set**                  | 用于训练神经网络的大数据集，提供自主学习能力                                                                                                              |
| **One Shot Learning**          | 使用单个样本进行类别识别的学习方式                                                                                                                        |
| **K-way, N-shot**              | Support Set包含k个类别，每个类别有n个样本                                                                                                                 |
| **相似度函数**                 | $sim(x, x')$，理想情况下同类为1，异类为0，常作为标签                                                                                                      |

## 参考资料

[1] [正则化理解 - 知乎](https://zhuanlan.zhihu.com/p/29957294)  
[2] [正则化相关问题 - 知乎](https://www.zhihu.com/question/38102762)
