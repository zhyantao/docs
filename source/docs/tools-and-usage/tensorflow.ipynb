{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0484b69",
   "metadata": {},
   "source": [
    "# Tensorflow 入门"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "084be89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e67fdb",
   "metadata": {},
   "source": [
    "## 数据表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670fbe3",
   "metadata": {},
   "source": [
    "### 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ecba44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(3.0)\n",
    "b = tf.constant(2.0)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75330f2b",
   "metadata": {},
   "source": [
    "### 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7232783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 1., 2., 3.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(4, dtype=tf.float32)\n",
    "y = tf.ones(4)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318e2b9",
   "metadata": {},
   "source": [
    "### 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be06e353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       " array([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       " array([[2., 1., 4., 3.],\n",
       "        [1., 2., 3., 4.],\n",
       "        [4., 3., 2., 1.]], dtype=float32)>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.reshape(tf.range(12, dtype=tf.float32), (3, 4))\n",
    "B = tf.constant([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de4714",
   "metadata": {},
   "source": [
    "### 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c23f7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4, 3), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14],\n",
       "        [15, 16, 17],\n",
       "        [18, 19, 20],\n",
       "        [21, 22, 23]],\n",
       "\n",
       "       [[24, 25, 26],\n",
       "        [27, 28, 29],\n",
       "        [30, 31, 32],\n",
       "        [33, 34, 35]]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.reshape(tf.range(36), (3, 4, -1))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205800a",
   "metadata": {},
   "source": [
    "## 属性和方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5399ca",
   "metadata": {},
   "source": [
    "### shape 和 size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2133b88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([4]),\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=4>,\n",
       " TensorShape([3, 4, 3]),\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=36>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, tf.size(x), X.shape, tf.size(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db35d0e",
   "metadata": {},
   "source": [
    "### reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2cdb153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
       "       [ 6.,  7.,  8.,  9., 10., 11.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(A, (2, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6106cb",
   "metadata": {},
   "source": [
    "### zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d89ad4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b81460",
   "metadata": {},
   "source": [
    "### random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff1810f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[-0.46702012,  0.67534786, -0.6981605 ,  1.1733029 ],\n",
       "       [-0.1361544 ,  0.02544517,  1.4528071 , -2.384327  ],\n",
       "       [ 0.4424338 , -1.5850155 ,  0.07943147, -0.51035947]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=[3, 4])  # 符合正态分布的随机数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323f45f5",
   "metadata": {},
   "source": [
    "### concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70d578b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(6, 4), dtype=float32, numpy=\n",
       " array([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [ 2.,  1.,  4.,  3.],\n",
       "        [ 1.,  2.,  3.,  4.],\n",
       "        [ 4.,  3.,  2.,  1.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 8), dtype=float32, numpy=\n",
       " array([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]], dtype=float32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([A, B], axis=0), tf.concat([A, B], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8261629",
   "metadata": {},
   "source": [
    "### 求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fa17667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 3), dtype=int32, numpy=array([[[198, 210, 222]]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对所有元素求和（这是一种降维方法）\n",
    "sum_total = tf.reduce_sum(X)\n",
    "sum_total\n",
    "\n",
    "# 指定 axis 求行和或列和，keepdims=True 保持轴数不变，可以方便后期利用广播机制\n",
    "sum_X = tf.reduce_sum(X, axis=[0,1], keepdims=True)\n",
    "sum_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f540c5",
   "metadata": {},
   "source": [
    "### 获取切片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d82d27",
   "metadata": {},
   "source": [
    "值得注意的是，图像一般默认为`(H, W, C)`即 (高度, 宽度, 通道数) 但获取切片时的参数一般为`(C, H, W)`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8dd49e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 4, 3), dtype=int32, numpy=\n",
       " array([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]],\n",
       " \n",
       "        [[12, 13, 14],\n",
       "         [15, 16, 17],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23]],\n",
       " \n",
       "        [[24, 25, 26],\n",
       "         [27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]]])>,\n",
       " <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
       " array([[24, 25, 26],\n",
       "        [27, 28, 29],\n",
       "        [30, 31, 32],\n",
       "        [33, 34, 35]])>,\n",
       " <tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy=\n",
       " array([[[12, 13, 14],\n",
       "         [15, 16, 17],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23]],\n",
       " \n",
       "        [[24, 25, 26],\n",
       "         [27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]]])>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X[-1], X[1:3] # 把 X 想成是图片的三个通道，X[-1] 获取最后一个通道，X[1:3] 获取第 2 和第 3 通道。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1733ed",
   "metadata": {},
   "source": [
    "## 代数运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a9cfe9",
   "metadata": {},
   "source": [
    "### 向量 $\\times$ 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66f7eb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 1., 2., 3.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, tf.tensordot(x, y, axes=1) # 点积后是一个标量，且 x 和 y 的数据类型保持一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd50675",
   "metadata": {},
   "source": [
    "### 矩阵 $\\times$ 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5473cbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       " array([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 1., 2., 3.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([14., 38., 62.], dtype=float32)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, x, tf.linalg.matvec(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b00389",
   "metadata": {},
   "source": [
    "### 矩阵 $\\times$ 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "177b09fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       " array([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       " array([[2., 1., 4., 3.],\n",
       "        [1., 2., 3., 4.],\n",
       "        [4., 3., 2., 1.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       " array([[36., 32., 28., 24.],\n",
       "        [43., 38., 37., 32.],\n",
       "        [50., 44., 46., 40.],\n",
       "        [57., 50., 55., 48.]], dtype=float32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B, tf.matmul(tf.transpose(A), B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6818e7",
   "metadata": {},
   "source": [
    "### 范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d44747ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.7416573>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 范数 和 2 范数\n",
    "tf.reduce_sum(tf.abs(x)), tf.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc55d65",
   "metadata": {},
   "source": [
    "## 运算符"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518dec5",
   "metadata": {},
   "source": [
    "### 加减乘除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ba3e021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-1.,  0.,  1.,  2.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 1., 2., 3.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 1., 2., 3.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 1., 2., 3.], dtype=float32)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y, x - y, x * y, x / y, x ** y  # ** 运算符是求幂运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf659d8",
   "metadata": {},
   "source": [
    "### 广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d4ce6",
   "metadata": {},
   "source": [
    "广播机制让形状不同的张量也能计算。它先将两个向量扩张成一致的形状（两个向量先变成矩阵），然后再相加（矩阵加法）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a2165c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = tf.reshape(y, (4, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7a8227e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 1., 2., 3.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       " array([[1., 2., 3., 4.],\n",
       "        [1., 2., 3., 4.],\n",
       "        [1., 2., 3., 4.],\n",
       "        [1., 2., 3., 4.]], dtype=float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, yt, x + yt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb555a",
   "metadata": {},
   "source": [
    "### 逻辑运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42cce1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=bool, numpy=\n",
       "array([[False,  True, False,  True],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A == B # 逻辑运算符“按元素”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8cf6c",
   "metadata": {},
   "source": [
    "## 声明变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c24a74",
   "metadata": {},
   "source": [
    "TensorFlow 中的 `Tensors` 是不可变的，也不能被赋值。 TensorFlow 中的 `Variables` 是支持赋值的可变容器。 请记住，TensorFlow 中的梯度不会通过 `Variable` 反向传播，**这句话没说错**，记住。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "443ebebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 4, 3), dtype=int32, numpy=\n",
       " array([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]],\n",
       " \n",
       "        [[12, 13, 14],\n",
       "         [15, 16, 17],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23]],\n",
       " \n",
       "        [[24, 25, 26],\n",
       "         [27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]]])>,\n",
       " <tf.Variable 'Variable:0' shape=(3, 4, 3) dtype=int32, numpy=\n",
       " array([[[12, 12, 12],\n",
       "         [12, 12, 12],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]],\n",
       " \n",
       "        [[12, 12, 12],\n",
       "         [12, 12, 12],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23]],\n",
       " \n",
       "        [[24, 25, 26],\n",
       "         [27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]]])>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_var = tf.Variable(X) # 声明变量，预分配存储空间\n",
    "X_var[0:2, 0:2, :].assign(tf.ones(X_var[0:2, 0:2, :].shape, dtype = tf.int32) * 12) # 把前两个通道的前两行都变成 12\n",
    "X, X_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a374e31",
   "metadata": {},
   "source": [
    "## 节省内存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe21baca",
   "metadata": {},
   "source": [
    "节省内存的意思就是不要重复地开辟内存，尽量原地操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "132a4052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认行为\n",
    "before = id(y)\n",
    "y = y + x\n",
    "id(y) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dceb64ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(z): 2212507768816\n",
      "id(z): 2212507768816\n"
     ]
    }
   ],
   "source": [
    "# 节省内存的做法是使用切片\n",
    "z = tf.Variable(tf.zeros_like(y))\n",
    "print('id(z):', id(z))\n",
    "z.assign(x + y)\n",
    "print('id(z):', id(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1709f",
   "metadata": {},
   "source": [
    "由于 TensorFlow 的 `Tensors` 是不可变的，而且梯度不会通过 `Variable` 流动， 因此 TensorFlow 没有提供一种明确的方式来原地运行单个操作。\n",
    "\n",
    "但是，TensorFlow 提供了 `tf.function` 修饰符， 将计算封装在 TensorFlow 图中，该图在运行前经过编译和优化。 这允许 TensorFlow 删除未使用的值，并复用先前分配的且不再需要的值。 这样可以最大限度地减少 TensorFlow 计算的内存开销。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f626b4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 4.,  9., 14., 19.], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def computation(X, Y):\n",
    "    Z = tf.zeros_like(Y)  # 这个未使用的值将被删除\n",
    "    A = X + Y  # 当不再需要时，分配将被复用\n",
    "    B = A + Y\n",
    "    C = B + Y\n",
    "    return C + Y\n",
    "\n",
    "computation(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9315e9a4",
   "metadata": {},
   "source": [
    "## 类型转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0232541",
   "metadata": {},
   "source": [
    "Tensorflow 转换后的结果不共享内存。这个小的 **不便** 实际上是非常重要的：当你在 CPU 或 GPU 上执行操作的时候，如果 Python 的 NumPy 包也 **希望使用相同的内存块** 执行其他操作，你不希望停下计算来等它。这个不便之处，MXNet 和 Tensorflow 都没有解决，**只有** PyTorch 是解决了的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8178a00",
   "metadata": {},
   "source": [
    "### tensor 转 ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ad83a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14],\n",
       "        [15, 16, 17],\n",
       "        [18, 19, 20],\n",
       "        [21, 22, 23]],\n",
       "\n",
       "       [[24, 25, 26],\n",
       "        [27, 28, 29],\n",
       "        [30, 31, 32],\n",
       "        [33, 34, 35]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74985c",
   "metadata": {},
   "source": [
    "### ndarray 转 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd3ecc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.,  7.],\n",
       "       [ 8.,  9., 10., 11.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b019f7",
   "metadata": {},
   "source": [
    "### tensor 转 scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "767f7b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([3.5]).numpy().item() # 仅限只含一个元素"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833620ae",
   "metadata": {},
   "source": [
    "## 自动求导"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6260204",
   "metadata": {},
   "source": [
    "这可能是最重要的部分了，有了上面的基础，相信这部分很容易看懂的。\n",
    "\n",
    "需要求导的函数：\n",
    "\n",
    "$$\n",
    "y = x^2 \\\\\n",
    "u = y\\\\\n",
    "z = u * x\n",
    "$$\n",
    "\n",
    "其中，变量 $x$ 的取值点为 $(0, 1, 2, 3)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b9b693d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.,  1.,  8., 27.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 1., 4., 9.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True,  True,  True,  True])>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(4, dtype=tf.float32) # 初始化数据\n",
    "x = tf.Variable(x) # 声明变量\n",
    "\n",
    "# 把所有计算记录在磁带（GradientTape()）上，可以把磁带想象成一种资源，可能是计算图吧\n",
    "with tf.GradientTape(persistent=True) as t: # 设置 persistent=True 来运行 t.gradient 多次\n",
    "    y = x * x\n",
    "    u = tf.stop_gradient(y) # 分离计算\n",
    "    z = u * x\n",
    "\n",
    "x_grad = t.gradient(z, x) # 求梯度\n",
    "\n",
    "z, x_grad, x_grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20b665a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.,  1.,  8., 27.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.,  3., 12., 27.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False, False])>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(4, dtype=tf.float32) # 初始化数据\n",
    "x = tf.Variable(x) # 声明变量\n",
    "\n",
    "# 把所有计算记录在磁带（GradientTape()）上，可以把磁带想象成一种资源，可能是计算图吧\n",
    "with tf.GradientTape(persistent=True) as t: # 设置 persistent=True 来运行 t.gradient 多次\n",
    "    y = x * x\n",
    "    u = y # 没有分离计算\n",
    "    z = u * x\n",
    "\n",
    "x_grad = t.gradient(z, x) # 求梯度\n",
    "\n",
    "z, x_grad, x_grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353a79a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "258d2c753b0026e96f7157f4eeab9794a11ae615406e567f5d076f348738e54a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
